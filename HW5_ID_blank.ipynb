{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a564fce",
   "metadata": {},
   "source": [
    "# HW Instructions\n",
    "\n",
    "In this exercise, you will be working with the ViT model for image classification using the CIFAR10 dataset. \n",
    "\n",
    "The task will involve going through the full machine learning lifecycle, including: preprocessing and exploratory data analysis, model implementation and training, tuning, and evaluation. \n",
    "\n",
    "It is assumed that you have some prior experience in the field from previous assignments. This assignment allows for flexibility in exploring and implementing solutions as you see fit.\n",
    "Make sure you read the instructions carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "875688b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T16:08:41.111048Z",
     "start_time": "2023-01-25T16:08:35.411470Z"
    }
   },
   "outputs": [],
   "source": [
    "# feel free to add any imports you might need (as long as it is part of the course environment)\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models.vision_transformer import Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6551efe",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13f23bba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T16:08:55.557534Z",
     "start_time": "2023-01-25T16:08:55.543181Z"
    }
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10('./', train=True, download=True, transform=train_transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10('./', train=False, download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "908bba6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T12:37:01.900648Z",
     "start_time": "2023-01-25T12:37:01.893597Z"
    }
   },
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# TO DO:                                                                    #\n",
    "# plot a couple of images with their corresponding labels                   #\n",
    "#############################################################################\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b77dc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T06:37:07.431838Z",
     "start_time": "2023-01-25T06:37:07.431838Z"
    }
   },
   "source": [
    "## A bit of exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f325ee7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T12:37:19.857126Z",
     "start_time": "2023-01-25T12:37:19.833453Z"
    }
   },
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# TO DO:                                                                    #\n",
    "# Figure out the size of the dataset:                                       #\n",
    "# How many samples in train/test?                                            #\n",
    "# How many labels? How many samples per label?                              #\n",
    "# Try access train_dataset.__dict__.keys() to see which attributes          #\n",
    "# are available on train_dataset.                                           #\n",
    "#############################################################################\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdcbfcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T06:37:07.431838Z",
     "start_time": "2023-01-25T06:37:07.431838Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3be793ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T06:37:07.431838Z",
     "start_time": "2023-01-25T06:37:07.431838Z"
    }
   },
   "source": [
    "## Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "184f8bf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T12:58:38.646695Z",
     "start_time": "2023-01-25T12:58:38.618509Z"
    }
   },
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# TO DO:                                                                    #\n",
    "# Decide on a batch size (which later can be tunned)                        #\n",
    "#############################################################################\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eca23a",
   "metadata": {},
   "source": [
    "# Building ViT Model\n",
    "\n",
    "In the next section, you will construct a Vision Transformer, a transformer-based image classifier. The goal of the ViT model is to bring advancements from the natural language processing field to computer vision. \n",
    "\n",
    "For this exercise, you will be required to implement the ViT model using a pre-built Encoder from the PyTorch library. Building the encoder can be challenging, so we have eliminated that step for you. If you are not familiar with the ViT model, it is highly recommended that you gain an understanding of its workings before beginning implementation. There is a ton of information available online, here is a pretty informative source:\n",
    "https://www.kaggle.com/code/abhinand05/vision-transformer-vit-tutorial-baseline\n",
    "\n",
    "In this assignment, you will be using a pre-built Encoder from the PyTorch library, which has already been loaded in the provided code. Therefore, you do not need to worry about the complexities of transformer computations when referring to the link provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c58d4d88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T12:42:59.357101Z",
     "start_time": "2023-01-25T12:42:59.315567Z"
    }
   },
   "outputs": [],
   "source": [
    "class ViT(nn.Module):\n",
    "    def __init__(self, image_size, patch_size, num_classes, num_layers, num_heads, hidden_dim, \n",
    "                 mlp_dim, dropout, attention_dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        #############################################################################\n",
    "        # TO DO:                                                                    #\n",
    "        # Initiate the required layers for your ViT model implementation.           #\n",
    "        # Hint: For the curious among us, you can pick at pytorch's                 #\n",
    "        # official implemetantion of vit (vit_b_16).                                #\n",
    "        #############################################################################\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # initializing the encoder backbone\n",
    "        # you should calculate the seq_length\n",
    "        self.encoder = Encoder(\n",
    "        seq_length=seq_length,\n",
    "        num_layers=num_layers,\n",
    "        num_heads=num_heads,\n",
    "        hidden_dim=hidden_dim,\n",
    "        mlp_dim=mlp_dim,\n",
    "        dropout=dropout,\n",
    "        attention_dropout=attention_dropout\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "        #############################################################################\n",
    "        # TO DO:                                                                    #\n",
    "        # Complete the rest of the class (foward method and other helper            #\n",
    "        # functions if needed).                                                     #\n",
    "        #############################################################################\n",
    "\n",
    "\n",
    "\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "65bf6f2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T06:43:11.302604Z",
     "start_time": "2023-01-25T06:43:11.280571Z"
    }
   },
   "outputs": [],
   "source": [
    "# this is just a simple initialization, feel free to change it.\n",
    "model = ViT(image_size=32, patch_size=8, num_classes=100, num_layers=2, num_heads=2, hidden_dim=128, \n",
    "                 mlp_dim=512, dropout=0.0, attention_dropout=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56cb757",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T06:43:11.302604Z",
     "start_time": "2023-01-25T06:43:11.280571Z"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3559b5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T06:43:11.302604Z",
     "start_time": "2023-01-25T06:43:11.280571Z"
    }
   },
   "source": [
    "## IMPORTANT READ!\n",
    "\n",
    "In the following section, you will be required to train your implementation of the ViT model as in previous assignments. However, it is important to note that training transformers can be challenging, especially when starting from scratch, as is the case in this exercise.\n",
    "\n",
    "It is acceptable if your final model does not achieve a high accuracy score, but it is crucial to document your training experiments and demonstrate that the model is able to train correctly (i.e. the loss decreases over time). This includes noting what you tried, what parameters worked best, and providing the loss and accuracy graphs as instructed in the next sections.\n",
    "\n",
    "A reference for training ViT on CIFAR10 can be found at https://github.com/omihub777/ViT-CIFAR. However, it's important to note that in the provided reference, the ViT model was trained using 200 epochs and over 2 hours of training.\n",
    "\n",
    "Note 1: If the loss decreases and your model trains correctly, you are on the safe side. The focus should be on the experiments and the things you tried.\n",
    "\n",
    "Note 2: The main goal is not to achieve a high accuracy score but to demonstrate that you understand the process.\n",
    "\n",
    "Note 3: If your final model's performance is strictly better than a random model (accuracy of around 1/num_classes) and you have provided thorough documentation of your experiments and processes, you will receive full credit for the assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "908db706",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T16:28:21.277541Z",
     "start_time": "2023-01-25T16:28:21.272626Z"
    }
   },
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# TO DO:                                                                    #\n",
    "# Create a validation set from the training set\n",
    "# Implement the training loop\n",
    "# Save the loss and accuracy for both training/validation sets every couple of iterations for plotting afterwards.\n",
    "#############################################################################\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22551fa9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T06:43:11.302604Z",
     "start_time": "2023-01-25T06:43:11.280571Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0efad2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T06:43:11.608428Z",
     "start_time": "2023-01-25T06:43:11.599050Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f99b7d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T12:55:40.946033Z",
     "start_time": "2023-01-25T12:55:28.307043Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f0884e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T06:19:38.647220Z",
     "start_time": "2023-01-25T06:19:38.623653Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a643c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T19:03:29.226385Z",
     "start_time": "2023-01-24T19:03:29.207823Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08502cbe",
   "metadata": {},
   "source": [
    "## Loss and Acurracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "193842d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T11:28:35.888851Z",
     "start_time": "2023-01-25T11:28:35.864407Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot 2 graphs:\n",
    "# Graph 1: Loss vs itreation for training and validation sets\n",
    "# Graph 2: Accuracy vs itreation for training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64b628d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c9669c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372922fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e301ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc910f60",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1843b27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T12:53:05.024507Z",
     "start_time": "2023-01-25T12:53:05.012654Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the accuracy of the final model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7690bea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T13:05:04.193456Z",
     "start_time": "2023-01-25T13:05:04.184165Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3565cb50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T13:04:45.208953Z",
     "start_time": "2023-01-25T13:04:45.174084Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b6af3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbf62c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39977afa",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dcb5c7",
   "metadata": {},
   "source": [
    "##**Question:** \n",
    "\n",
    "Explain the importance of the positional embedding in the ViT model.\n",
    "\n",
    "**Your answer:** *Fill this in*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac22b7f",
   "metadata": {},
   "source": [
    "##**Question:** \n",
    "\n",
    "How would you evaluate the model if the number of samples per class would not be balanced?\n",
    "How can you deal with class imbalance on multiclass classification?\n",
    "\n",
    "**Your answer:** *Fill this in*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0628ab06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f7ec4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
